{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-18T02:17:24.109374Z","iopub.execute_input":"2023-05-18T02:17:24.109814Z","iopub.status.idle":"2023-05-18T02:17:24.119153Z","shell.execute_reply.started":"2023-05-18T02:17:24.109777Z","shell.execute_reply":"2023-05-18T02:17:24.117906Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"**Human Weight Prediction**\nData wrangling, transfor and analysis. Spark ML model, creating, saving and loading.\n\nObjectives:\n\n* Data web scraping, cleaning and transform data into a dataframe\n* Create a simple Linear Regression Model, save and load the SparkML model\n* Make predictions using the loaded SparkML model\n\nAcknowledgement: SOCR Data Dinov 020108 HeightsWeights\nLink: http://socr.ucla.edu/docs/resources/SOCR_Data/SOCR_Data_Dinov_020108_HeightsWeights.html","metadata":{}},{"cell_type":"code","source":"# Import pandas as pd\nimport pandas as pd\n\n# Define path to HTML file\nhtml_path = 'http://socr.ucla.edu/docs/resources/SOCR_Data/SOCR_Data_Dinov_020108_HeightsWeights.html'\n\n# Read tables from HTML file and pass to pandas dataframe\ntable = pd.read_html(html_path)\ndf = table[0]\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:14:28.257481Z","iopub.execute_input":"2023-05-18T02:14:28.257862Z","iopub.status.idle":"2023-05-18T02:14:54.363314Z","shell.execute_reply.started":"2023-05-18T02:14:28.257831Z","shell.execute_reply":"2023-05-18T02:14:54.362115Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"       0               1               2\n0  Index  Height(Inches)  Weight(Pounds)\n1      1        65.78331        112.9925\n2      2        71.51521        136.4873\n3      3        69.39874        153.0269\n4      4         68.2166        142.3354","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Index</td>\n      <td>Height(Inches)</td>\n      <td>Weight(Pounds)</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>65.78331</td>\n      <td>112.9925</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>71.51521</td>\n      <td>136.4873</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>69.39874</td>\n      <td>153.0269</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>68.2166</td>\n      <td>142.3354</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.drop(index=df.index[0],inplace=True) # Drop first row\ndel df[0] # Delete Index column\ndf = df.astype(float) # Change value types (string into float)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:15:03.393946Z","iopub.execute_input":"2023-05-18T02:15:03.394399Z","iopub.status.idle":"2023-05-18T02:15:03.424838Z","shell.execute_reply.started":"2023-05-18T02:15:03.394359Z","shell.execute_reply":"2023-05-18T02:15:03.423756Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"          1         2\n1  65.78331  112.9925\n2  71.51521  136.4873\n3  69.39874  153.0269\n4  68.21660  142.3354\n5  67.78781  144.2971","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>65.78331</td>\n      <td>112.9925</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>71.51521</td>\n      <td>136.4873</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>69.39874</td>\n      <td>153.0269</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>68.21660</td>\n      <td>142.3354</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>67.78781</td>\n      <td>144.2971</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Metric conversions\n\n# Convert inches to cm\ndf[1] = 2.54 * df[1]\n\n# Convert pounds to kg\ndf[2] = df[2] * 0.453592\n\ndf = df.round(2) # Round to two decimals\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:15:07.713766Z","iopub.execute_input":"2023-05-18T02:15:07.714164Z","iopub.status.idle":"2023-05-18T02:15:07.733700Z","shell.execute_reply.started":"2023-05-18T02:15:07.714131Z","shell.execute_reply":"2023-05-18T02:15:07.732471Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"        1      2\n1  167.09  51.25\n2  181.65  61.91\n3  176.27  69.41\n4  173.27  64.56\n5  172.18  65.45","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1</th>\n      <th>2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>167.09</td>\n      <td>51.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>181.65</td>\n      <td>61.91</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>176.27</td>\n      <td>69.41</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>173.27</td>\n      <td>64.56</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>172.18</td>\n      <td>65.45</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Install spark\n!pip install pyspark\n!pip install findspark\nimport findspark\nfindspark.init()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:15:13.160439Z","iopub.execute_input":"2023-05-18T02:15:13.160848Z","iopub.status.idle":"2023-05-18T02:16:18.117795Z","shell.execute_reply.started":"2023-05-18T02:15:13.160813Z","shell.execute_reply":"2023-05-18T02:16:18.116527Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting pyspark\n  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\nBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317146 sha256=b90abe192928e5daf81df86533b4041e010738d3500a54b9eda1f81861f22d6c\n  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\nSuccessfully built pyspark\nInstalling collected packages: pyspark\nSuccessfully installed pyspark-3.4.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mCollecting findspark\n  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\nInstalling collected packages: findspark\nSuccessfully installed findspark-2.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# Start Spark session\n\n# Import pyspark, Spark API for Python \nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\n# Creating a spark context class\nsc = SparkContext()\n\n# Creating a spark session\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Python Spark DataFrames basic example\") \\\n    .config(\"spark.some.config.option\", \"some-value\") \\\n    .getOrCreate()\n\n# Start sesion\nspark","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:16:32.364924Z","iopub.execute_input":"2023-05-18T02:16:32.365334Z","iopub.status.idle":"2023-05-18T02:16:39.499375Z","shell.execute_reply.started":"2023-05-18T02:16:32.365298Z","shell.execute_reply":"2023-05-18T02:16:39.498109Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"Setting default log level to \"WARN\".\nTo adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n23/05/18 02:16:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7bf534285db0>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://398065717d44:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.4.0</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}]},{"cell_type":"code","source":"# Create PySpark DataFrame from Pandas\n\ncolumns = ['height', 'weight']\n\ndataframe = spark.createDataFrame(df, columns)\ndataframe.printSchema()\ndataframe.show(5)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:16:45.931816Z","iopub.execute_input":"2023-05-18T02:16:45.932335Z","iopub.status.idle":"2023-05-18T02:16:52.944533Z","shell.execute_reply.started":"2023-05-18T02:16:45.932290Z","shell.execute_reply":"2023-05-18T02:16:52.943703Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"root\n |-- height: double (nullable = true)\n |-- weight: double (nullable = true)\n\n","output_type":"stream"},{"name":"stderr","text":"[Stage 0:>                                                          (0 + 1) / 1]\r","output_type":"stream"},{"name":"stdout","text":"+------+------+\n|height|weight|\n+------+------+\n|167.09| 51.25|\n|181.65| 61.91|\n|176.27| 69.41|\n|173.27| 64.56|\n|172.18| 65.45|\n+------+------+\nonly showing top 5 rows\n\n","output_type":"stream"},{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Import Spark ML libraries\n\nimport findspark\nfindspark.init()\n\nfrom pyspark import SparkContext, SparkConf\nfrom pyspark.sql import SparkSession\n\nfrom pyspark.ml.feature import VectorAssembler\nfrom pyspark.ml.regression import LinearRegression\n","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:17:06.640891Z","iopub.execute_input":"2023-05-18T02:17:06.641344Z","iopub.status.idle":"2023-05-18T02:17:06.921742Z","shell.execute_reply.started":"2023-05-18T02:17:06.641311Z","shell.execute_reply":"2023-05-18T02:17:06.920411Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Converting data frame columns into feature vectors\n\nassembler = VectorAssembler(\n    inputCols=['height'],\n    outputCol='features')\n\ndata = assembler.transform(dataframe).select('features','weight')\ndata.show(5)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:17:52.136485Z","iopub.execute_input":"2023-05-18T02:17:52.136908Z","iopub.status.idle":"2023-05-18T02:17:53.475269Z","shell.execute_reply.started":"2023-05-18T02:17:52.136872Z","shell.execute_reply":"2023-05-18T02:17:53.473822Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"+--------+------+\n|features|weight|\n+--------+------+\n|[167.09]| 51.25|\n|[181.65]| 61.91|\n|[176.27]| 69.41|\n|[173.27]| 64.56|\n|[172.18]| 65.45|\n+--------+------+\nonly showing top 5 rows\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create and Train model\nlr = LinearRegression(featuresCol='features', labelCol='weight', maxIter=100)\nlr.setRegParam(0.1)\n\n# Fit the model\nlrModel = lr.fit(data)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:18:43.341965Z","iopub.execute_input":"2023-05-18T02:18:43.342426Z","iopub.status.idle":"2023-05-18T02:18:46.979322Z","shell.execute_reply.started":"2023-05-18T02:18:43.342392Z","shell.execute_reply":"2023-05-18T02:18:46.977942Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"23/05/18 02:18:44 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n23/05/18 02:18:45 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Save the model Human Weight and Height \nlrModel.save('human_height.model')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:19:23.410662Z","iopub.execute_input":"2023-05-18T02:19:23.411073Z","iopub.status.idle":"2023-05-18T02:19:25.302449Z","shell.execute_reply.started":"2023-05-18T02:19:23.411042Z","shell.execute_reply":"2023-05-18T02:19:25.301041Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"                                                                                \r","output_type":"stream"}]},{"cell_type":"code","source":"# Load the model\nfrom pyspark.ml.regression import LinearRegressionModel # LinearRegressionModel to load the model\nmodel = LinearRegressionModel.load('human_height.model')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:19:59.023765Z","iopub.execute_input":"2023-05-18T02:19:59.024261Z","iopub.status.idle":"2023-05-18T02:20:00.118050Z","shell.execute_reply.started":"2023-05-18T02:19:59.024219Z","shell.execute_reply":"2023-05-18T02:20:00.116694Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Make Prediction\n\n# This function converts a scalar number into a dataframe that can be used by the model to predict.\ndef predict(weight):\n    assembler = VectorAssembler(inputCols=[\"weight\"],outputCol=\"features\")\n    data = [[weight,0]]\n    columns = [\"weight\", \"height\"]\n    _ = spark.createDataFrame(data, columns)\n    __ = assembler.transform(_).select('features','height')\n    predictions = model.transform(__)\n    predictions.select('prediction').show()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:20:52.012738Z","iopub.execute_input":"2023-05-18T02:20:52.013163Z","iopub.status.idle":"2023-05-18T02:20:52.020240Z","shell.execute_reply.started":"2023-05-18T02:20:52.013130Z","shell.execute_reply":"2023-05-18T02:20:52.019337Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Predict the weight of person who height is 170 cm\npredict(170)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:22:12.765478Z","iopub.execute_input":"2023-05-18T02:22:12.765900Z","iopub.status.idle":"2023-05-18T02:22:13.509790Z","shell.execute_reply.started":"2023-05-18T02:22:12.765870Z","shell.execute_reply":"2023-05-18T02:22:13.508565Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"+-----------------+\n|       prediction|\n+-----------------+\n|56.18174659878049|\n+-----------------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predict the weight of person who height is 170 cm\npredict(150)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:22:30.232106Z","iopub.execute_input":"2023-05-18T02:22:30.232485Z","iopub.status.idle":"2023-05-18T02:22:30.990349Z","shell.execute_reply.started":"2023-05-18T02:22:30.232456Z","shell.execute_reply":"2023-05-18T02:22:30.989479Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"+-----------------+\n|       prediction|\n+-----------------+\n|45.37342510832839|\n+-----------------+\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Predict the weight of person who height is 170 cm\npredict(200)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T02:22:48.726531Z","iopub.execute_input":"2023-05-18T02:22:48.726908Z","iopub.status.idle":"2023-05-18T02:22:49.444516Z","shell.execute_reply.started":"2023-05-18T02:22:48.726878Z","shell.execute_reply":"2023-05-18T02:22:49.443429Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"+-----------------+\n|       prediction|\n+-----------------+\n|72.39422883445864|\n+-----------------+\n\n","output_type":"stream"}]}]}